{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt # Keep for potential debugging/local plotting\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Subset, random_split\nfrom torchvision import transforms, models # Import models\nfrom torchvision.datasets import ImageFolder # Use standard ImageFolder\nfrom PIL import Image\nfrom collections import deque\nimport random\nimport time\nimport wandb\nimport logging\nfrom tqdm.notebook import tqdm # Use notebook version for Kaggle UI\nimport argparse # Keep for structure, but values often fixed/from wandb\nimport copy # Needed to save best model state\nfrom wandb.sdk.wandb_settings import Settings # For timeout setting\n\n# =============================================================================\n# W&B Login (Using Kaggle Secrets or Environment Variable)\n# =============================================================================\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n    wandb.login(key=wandb_api_key)\n    print(\"W&B login successful using Kaggle Secret.\")\nexcept ImportError:\n    print(\"kaggle_secrets not found. Ensure it's enabled or use interactive/env var login.\")\n    wandb.login()\nexcept Exception as e:\n     print(f\"W&B login using Kaggle Secret failed: {e}. Trying other methods.\")\n     wandb.login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" =============================================================================\n# Configuration (Define fixed settings and default HPARAMS here)\n# =============================================================================\n# --- Fixed Settings ---\n# <<< VERIFY THIS PATH to your dataset input in Kaggle >>>\nDATA_DIR = \"/kaggle/input/inaturalist-12k/inaturalist_12K\"\nSEED = 42\nIMG_SIZE = 224 # ResNet usually uses 224\nNUM_WORKERS = 2 # Kaggle typical limit\nVAL_SPLIT = 0.2\nWANDB_PROJECT_NAME = \"CNN-iNaturalist-Scratch\" # <<< USE SAME PROJECT AS PART A\nWANDB_ENTITY = None # Optional: Let wandb infer or set \"user_or_team_name\"\nOUTPUT_DIR = \"/kaggle/working/output_partB\" # Save outputs here in Kaggle\nMODEL_SAVE_NAME = \"resnet50_finetuned_best.pth\"\n\n# --- Default Hyperparameters (will be overridden by W&B sweep config) ---\nDEFAULT_HPARAMS = {\n    'finetune_strategy': 'feature_extract',\n    'unfreeze_layers': 1, # K for unfreeze_last_k\n    'learning_rate': 0.001,\n    'weight_decay': 0,\n    'batch_size': 32,\n    'epochs': 15,\n    'optimizer': 'adam', # Default optimizer\n    'seed': SEED # Include seed in config logged\n}\n\n# --- Setup Logging ---\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s', stream=sys.stdout)\n\n# =============================================================================\n# Utility Functions and Classes\n# =============================================================================\n\n# --- From utils_b.py ---\ndef set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    logging.debug(f\"Seed set to {seed}\")\n\ndef seed_worker(worker_id):\n    worker_seed = (torch.initial_seed()) % 2**32\n    np.random.seed(worker_seed); random.seed(worker_seed)\n    logging.debug(f\"Worker {worker_id} seeded with {worker_seed}\")\n\ng_dataloader_seed_b = torch.Generator()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Helper Class for Applying Transforms to Subsets ---\nclass TransformedSubset(Dataset):\n    \"\"\" Applies a transform to a Subset. \"\"\"\n    def __init__(self, subset, transform=None):\n        self.subset = subset; self.transform = transform\n    def __getitem__(self, index):\n        x, y = self.subset[index] # Gets PIL Image from ImageFolder subset\n        if self.transform: x = self.transform(x)\n        return x, y\n    def __len__(self): return len(self.subset)\n\n# --- From dataset_b.py ---\ndef get_data_loaders_b(data_dir, batch_size=32, val_split=0.2, num_workers=2, img_size=224, seed=42, generator=None):\n    \"\"\" Creates DataLoaders for fine-tuning ResNet50. \"\"\"\n    logging.info(f\"DataLoaders Part B: batch={batch_size}, val_split={val_split}, workers={num_workers}\")\n    if generator is None: generator = torch.Generator().manual_seed(seed)\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    target_input_size = img_size\n    train_transform = transforms.Compose([transforms.RandomResizedCrop(target_input_size, scale=(0.8, 1.0)), transforms.RandomHorizontalFlip(), transforms.ColorJitter(brightness=0.1, contrast=0.1), transforms.ToTensor(), normalize])\n    val_test_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(target_input_size), transforms.ToTensor(), normalize])\n    train_dir, test_dir = os.path.join(data_dir, 'train'), os.path.join(data_dir, 'test')\n    if not os.path.isdir(train_dir): raise FileNotFoundError(f\"Train dir missing: {train_dir}\")\n    if not os.path.isdir(test_dir): raise FileNotFoundError(f\"Test dir missing: {test_dir}\")\n    try:\n        full_train_dataset = ImageFolder(root=train_dir); test_dataset_pil = ImageFolder(root=test_dir)\n    except Exception as e: logging.error(f\"Dataset load error: {e}\"); raise e\n    targets = np.array([s[1] for s in full_train_dataset.samples]); dataset_size = len(targets); train_indices=[]; val_indices=[]; val_loader=None; num_classes=len(full_train_dataset.classes)\n    valid_indices = list(range(dataset_size)) # Assume all are valid initially\n    if 0<val_split<1 and dataset_size>=2 and num_classes>0:\n        local_rng=np.random.RandomState(seed); indices_by_class={lbl:[] for lbl in range(num_classes)}\n        for idx in valid_indices: indices_by_class[targets[idx]].append(idx)\n        for label,indices in indices_by_class.items():\n            n_cls=len(indices);\n            if n_cls==0: continue\n            local_rng.shuffle(indices); n_val=int(np.floor(val_split*n_cls))\n            if n_cls>1 and n_val==n_cls: n_val=n_cls-1\n            elif n_cls<=1 and val_split>0: n_val=0\n            val_indices.extend(indices[:n_val]); train_indices.extend(indices[n_val:])\n        if not train_indices or not val_indices: logging.warning(\"Split fail. Random split.\"); local_rng.shuffle(valid_indices); split_point=int(len(valid_indices)*(1-val_split)); train_indices=valid_indices[:split_point]; val_indices=valid_indices[split_point:]\n        logging.info(f\"Split (seed {seed}): {len(train_indices)} train, {len(val_indices)} val.\")\n        local_rng.shuffle(train_indices)\n        train_subset_pil = Subset(full_train_dataset, train_indices); val_subset_pil = Subset(full_train_dataset, val_indices)\n        train_dataset_transformed = TransformedSubset(train_subset_pil, transform=train_transform)\n        val_dataset_transformed = TransformedSubset(val_subset_pil, transform=val_test_transform)\n        val_loader = DataLoader(val_dataset_transformed, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available(), worker_init_fn=seed_worker if num_workers>0 else None, generator=generator if num_workers>0 else None)\n    else: logging.warning(\"Val split skipped.\"); train_indices=valid_indices; train_subset_pil = Subset(full_train_dataset, train_indices); train_dataset_transformed = TransformedSubset(train_subset_pil, transform=train_transform)\n    test_dataset_transformed = TransformedSubset(test_dataset_pil, transform=val_test_transform)\n    use_persistent_workers=num_workers>0 and sys.version_info>=(3,8); loader_kwargs={'persistent_workers':True,'prefetch_factor':2} if use_persistent_workers else {}\n    train_loader=DataLoader(train_dataset_transformed,batch_size=batch_size,shuffle=True,num_workers=num_workers,pin_memory=torch.cuda.is_available(),drop_last=True,worker_init_fn=seed_worker if num_workers>0 else None,generator=generator if num_workers>0 else None,**loader_kwargs)\n    test_loader=DataLoader(test_dataset_transformed,batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory=torch.cuda.is_available(),worker_init_fn=seed_worker if num_workers>0 else None,generator=generator if num_workers>0 else None,**loader_kwargs)\n    return train_loader, val_loader, test_loader, full_train_dataset.classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_parameter_requires_grad(model, strategy, num_unfreeze_layers=1):\n    \"\"\" Sets requires_grad based on fine-tuning strategy. \"\"\"\n    trainable_params = 0; total_params = sum(p.numel() for p in model.parameters())\n    if strategy == 'feature_extract':\n        logging.info(\"Strategy: Feature Extraction\")\n        for param in model.parameters(): param.requires_grad = False\n        if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):\n            for param in model.fc.parameters(): param.requires_grad = True\n            fc_params = sum(p.numel() for p in model.fc.parameters())\n            logging.info(f\" -> Unfrozen 'fc' ({fc_params:,} params).\")\n            trainable_params = fc_params\n        else: logging.warning(\"Could not find 'fc' layer.\")\n    elif strategy == 'finetune_all':\n        logging.info(\"Strategy: Fine-tuning All Layers\")\n        for param in model.parameters(): param.requires_grad = True\n        trainable_params = total_params\n    elif strategy == 'unfreeze_last_k':\n        k = num_unfreeze_layers; logging.info(f\"Strategy: Unfreezing last {k} block(s) + classifier\")\n        for param in model.parameters(): param.requires_grad = False\n        fc_params = 0\n        if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):\n            for param in model.fc.parameters(): param.requires_grad = True\n            fc_params = sum(p.numel() for p in model.fc.parameters())\n            logging.info(f\" -> Unfrozen 'fc' ({fc_params:,} params).\")\n        layer_names = [name for name,_ in model.named_children() if name.startswith('layer')]\n        k = max(0, min(k, len(layer_names))); layers_to_unfreeze = layer_names[-k:]\n        unfrozen_block_params = 0\n        if layers_to_unfreeze:\n            logging.info(f\" -> Unfreezing blocks: {layers_to_unfreeze}\")\n            for name, child in model.named_children():\n                if name in layers_to_unfreeze:\n                    for param in child.parameters(): param.requires_grad = True\n                    block_params = sum(p.numel() for p in child.parameters())\n                    unfrozen_block_params += block_params; logging.info(f\"    - Unfrozen '{name}' ({block_params:,} params).\")\n        trainable_params = fc_params + unfrozen_block_params\n    else: raise ValueError(f\"Unknown strategy: {strategy}\")\n    logging.info(f\"Model Parameters: Trainable={trainable_params:,} / Total={total_params:,}\")\n    return trainable_params, total_params","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================================================\n# Main Training Function (for W&B Agent)\n# =============================================================================\ndef train_finetune_trial():\n    \"\"\" Trains one fine-tuning trial based on wandb.config. \"\"\"\n    run = None\n    config = None\n    best_model_state = None\n    best_val_acc = 0.0\n    best_epoch = 0\n    # Initialize metrics\n    epoch_val_acc = float('nan'); epoch_val_loss = float('nan')\n    epoch_train_acc = 0.0; epoch_train_loss = float('nan')\n    epochs_run_actual = 0\n\n    try:\n        # --- Initialize W&B Run ---\n        run = wandb.init(settings=Settings(init_timeout=300))\n        # Use defaults if sweep doesn't provide a value (more robust)\n        config = wandb.config\n        hparams = {**DEFAULT_HPARAMS, **dict(config)} # Merge defaults with sweep config\n\n        # --- Set Run Name ---\n        try:\n            strategy_tag = hparams['finetune_strategy'][:4]\n            if hparams['finetune_strategy'] == 'unfreeze_last_k':\n                 strategy_tag += f\"k{hparams['unfreeze_layers']}\"\n            run_name = (f\"{strategy_tag}_bs{hparams['batch_size']}\"\n                        f\"_lr{hparams['learning_rate']:.1E}_wd{hparams['weight_decay']:.1E}\")\n            run_name = run_name.replace('.','p').replace('-','').replace('E','e')\n            wandb.run.name = run_name[:128]\n        except Exception as name_e:\n             logging.warning(f\"Could not set dynamic run name: {name_e}\")\n             wandb.run.name = f\"finetune-{run.id[:8]}\" # Fallback name\n\n        logging.info(f\"--- Starting Trial: {wandb.run.name} (ID: {run.id}) ---\")\n        logging.info(f\"Effective Config: {hparams}\") # Log the actual merged config used\n\n        # --- Setup ---\n        trial_seed = hparams['seed'] # Use seed from config\n        set_seed(trial_seed)\n        g_dataloader_seed_b.manual_seed(trial_seed)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.is_available(): torch.cuda.empty_cache()\n        logging.info(f\"Using device: {device}\")\n\n        # --- Data ---\n        train_loader, val_loader, test_loader, classes = get_data_loaders_b(\n            data_dir=DATA_DIR, batch_size=hparams['batch_size'], augment=True, # Assuming always augment\n            num_workers=NUM_WORKERS, img_size=IMG_SIZE, val_split=VAL_SPLIT, seed=trial_seed,\n            generator=g_dataloader_seed_b\n        )\n        num_classes = len(classes)\n\n        # --- Model ---\n        logging.info(\"Loading pre-trained ResNet50 model...\")\n        weights = models.ResNet50_Weights.IMAGENET1K_V1\n        model = models.resnet50(weights=weights)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes) # Replace head\n        logging.info(f\"Replaced final layer for {num_classes} classes.\")\n\n        # --- Apply Fine-tuning Strategy ---\n        trainable_params, total_params = set_parameter_requires_grad(\n            model, hparams['finetune_strategy'], hparams['unfreeze_layers']\n        )\n        model = model.to(device)\n\n        # --- Log Model Info ---\n        wandb.watch(model, log='gradients', log_freq=100)\n        # Update config logged to W&B with actual trainable params\n        wandb.config.update({\n            \"trainable_parameters\": trainable_params,\n            \"total_parameters\": total_params,\n            \"num_classes\": num_classes\n        }, allow_val_change=True)\n        logging.info(f\"Trainable Params: {trainable_params:,}, Total Params: {total_params:,}\")\n\n\n        # --- Loss, Optimizer, Scheduler ---\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n                               lr=hparams['learning_rate'],\n                               weight_decay=hparams['weight_decay'])\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=False)\n\n        # --- Training Loop ---\n        epochs_to_run = hparams['epochs']\n        logging.info(f\"Starting training for {epochs_to_run} epochs...\")\n\n        for epoch in range(epochs_to_run):\n            epochs_run_actual = epoch + 1; epoch_start_time = time.time()\n            # --- Training Epoch ---\n            model.train(); running_loss = 0.0; correct_train = 0; total_train = 0\n            train_pbar = tqdm(train_loader, desc=f\"Ep {epoch+1} Tr\", leave=False, file=sys.stdout)\n            for i, batch_data in enumerate(train_pbar):\n                 try: inputs, labels = batch_data; assert not torch.any(labels < 0)\n                 except: logging.warning(f\"Skip bad train batch {i}\"); continue\n                 inputs, labels = inputs.to(device), labels.to(device)\n                 try:\n                    optimizer.zero_grad(set_to_none=True); outputs = model(inputs)\n                    loss = criterion(outputs, labels); loss.backward(); optimizer.step()\n                    running_loss += loss.item() * inputs.size(0) # Accumulate total loss\n                    _, predicted = outputs.max(1)\n                    total_train += labels.size(0); correct_train += predicted.eq(labels).sum().item()\n                    if i % 20 == 0 and total_train > 0: train_pbar.set_postfix({'L': f'{running_loss/total_train:.3f}', 'Acc': f'{100.*correct_train/total_train:.1f}%'})\n                 except RuntimeError as e: logging.error(f\"Runtime error: {e}\"); torch.cuda.empty_cache(); raise e\n            train_pbar.close()\n            epoch_train_loss = running_loss/total_train if total_train>0 else 0\n            epoch_train_acc = 100.*correct_train/total_train if total_train>0 else 0\n\n            # --- Validation Epoch ---\n            epoch_val_loss = float('nan'); epoch_val_acc = float('nan') # Reset for epoch\n            if val_loader and len(val_loader) > 0:\n                model.eval(); val_correct = 0; val_total = 0; val_loss_accum = 0.0\n                val_pbar = tqdm(val_loader, desc=f\"Ep {epoch+1} Val\", leave=False, file=sys.stdout)\n                with torch.no_grad():\n                    for i_val, batch_data in enumerate(val_pbar):\n                        try: inputs, labels = batch_data; assert not torch.any(labels < 0)\n                        except: logging.warning(f\"Skip bad val batch {i_val}\"); continue\n                        inputs, labels = inputs.to(device), labels.to(device)\n                        try:\n                            outputs = model(inputs); loss = criterion(outputs, labels)\n                            val_loss_accum += loss.item() * inputs.size(0) # Accumulate total loss\n                            _, predicted = outputs.max(1)\n                            val_total += labels.size(0); val_correct += predicted.eq(labels).sum().item()\n                            if i_val % 10 == 0 and val_total > 0: val_pbar.set_postfix({'L': f'{val_loss_accum/val_total:.3f}', 'Acc': f'{100.*val_correct/val_total:.1f}%'})\n                        except RuntimeError as e: logging.error(f\"Val forward error: {e}\")\n                val_pbar.close()\n                if val_total > 0:\n                    epoch_val_loss = val_loss_accum / val_total # Average loss per sample\n                    epoch_val_acc = 100. * val_correct / val_total\n                    scheduler.step(epoch_val_acc) # Step based on validation accuracy\n\n            # --- Logging ---\n            epoch_duration = time.time() - epoch_start_time\n            log_dict = {'epoch': epoch+1, 'train_loss': epoch_train_loss, 'train_accuracy': epoch_train_acc, 'lr': optimizer.param_groups[0]['lr'], 'epoch_sec': epoch_duration}\n            if not np.isnan(epoch_val_loss): log_dict['val_loss'] = epoch_val_loss\n            if not np.isnan(epoch_val_acc): log_dict['val_accuracy'] = epoch_val_acc\n            wandb.log(log_dict, commit=True) # Log at end of epoch\n            logging.info(f'E{epoch+1}/{epochs_to_run}|Tr L:{epoch_train_loss:.3f},Tr Acc:{epoch_train_acc:.2f}%|'+(f'Val L:{epoch_val_loss:.3f},Val Acc:{epoch_val_acc:.2f}%|' if not np.isnan(epoch_val_acc) else 'Val:N/A|')+f'LR:{optimizer.param_groups[0][\"lr\"]:.1E}|T:{epoch_duration:.1f}s')\n\n            # --- Save Best Model State IN MEMORY ---\n            if not np.isnan(epoch_val_acc) and epoch_val_acc > best_val_acc:\n                best_val_acc = epoch_val_acc; best_epoch = epoch + 1\n                best_model_state = copy.deepcopy(model.state_dict())\n                logging.info(f\"*** Best val acc: {best_val_acc:.2f}% at Ep {best_epoch} ***\")\n\n            if torch.cuda.is_available(): torch.cuda.empty_cache() # Clear cache end of epoch\n\n        # --- End of Trial Summary Logging ---\n        final_best_val_acc = best_val_acc if best_epoch > 0 else (epoch_val_acc if not np.isnan(epoch_val_acc) else 0)\n        final_best_epoch = best_epoch if best_epoch > 0 else epochs_run_actual\n        wandb.run.summary[\"best_val_accuracy\"] = final_best_val_acc\n        wandb.run.summary[\"best_epoch\"] = final_best_epoch\n        wandb.run.summary[\"final_train_accuracy\"] = epoch_train_acc\n        wandb.run.summary[\"final_val_loss\"] = epoch_val_loss\n        wandb.run.summary[\"final_val_accuracy\"] = epoch_val_acc\n        wandb.run.summary[\"epochs_completed\"] = epochs_run_actual\n\n        logging.info(f\"--- Trial {wandb.run.name} Finished. Best Val Acc: {final_best_val_acc:.2f}% ---\")\n\n        # --- Optional: Save best model locally and as artifact ---\n        if best_model_state:\n            save_path = os.path.join(OUTPUT_DIR, f\"best_model_{run.id}.pth\")\n            os.makedirs(OUTPUT_DIR, exist_ok=True)\n            try:\n                save_dict = {'epoch': best_epoch, 'model_state_dict': best_model_state, 'best_val_accuracy': best_val_acc, 'config': hparams}\n                torch.save(save_dict, save_path)\n                logging.info(f\"Best model state saved locally to {save_path}\")\n                model_artifact = wandb.Artifact(f\"best-model-{run.id}\", type=\"model\", description=f\"Best ResNet50 fine-tuned model from run {run.name}\", metadata=hparams)\n                model_artifact.add_file(save_path)\n                wandb.log_artifact(model_artifact)\n                logging.info(\"Best model logged as W&B artifact.\")\n            except Exception as e: logging.error(f\"Failed to save/log best model state: {e}\")\n\n    except Exception as e:\n         logging.error(f\"Error during training trial {run.id if run else 'unknown'}: {e}\", exc_info=True)\n         if run and wandb.run:\n             try: wandb.log({\"error\": str(e)[:1024]}, commit=True)\n             except: pass\n             wandb.finish(exit_code=1)\n\n    finally:\n        # Ensure finish is called\n        if run and wandb.run is not None and wandb.run.id == run.id:\n             if hasattr(wandb.run, 'finished') and not wandb.run.finished:\n                 try: wandb.finish()\n                 except Exception as fe: logging.error(f\"Error finishing W&B run: {fe}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================================================================\n# Sweep Configuration Reference (for Part B sweep 'b49z6yly')\n# =============================================================================\nsweep_config_part_b_ref = {\n    'method': 'bayes',\n    'metric': {'name': 'best_val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'finetune_strategy': {'values': ['feature_extract', 'unfreeze_last_k', 'finetune_all']},\n        'unfreeze_layers': {'values': [1, 2, 3]},\n        'learning_rate': {'distribution': 'log_uniform_values', 'min': 1e-5, 'max': 5e-3},\n        'weight_decay': {'values': [0, 0.0001, 0.0005]},\n        'batch_size': {'values': [16, 32]},\n        'epochs': {'value': 15},\n        'seed': {'value': 42}\n        # --- Add other hyperparameters from your ACTUAL sweep config if different ---\n        # e.g., 'optimizer': {'values': ['adam']}\n        # e.g., 'hidden_size': {'values': [256]} # If Critic/Actor size was swept (unlikely needed)\n    }\n}\nprint(\"Sweep Configuration Reference (Agent uses actual config from W&B):\")\n# import json; print(json.dumps(sweep_config_part_b_ref, indent=2)) # Pretty print\n\n# =============================================================================\n# Start the W&B Agent for Part B Sweep\n# =============================================================================\nprint(f\"\\n--- Starting W&B Agent for Fine-tuning Sweep: {SWEEP_ID} ---\")\nprint(f\"--- Agent will run max {AGENT_RUN_COUNT if AGENT_RUN_COUNT else 'unlimited'} trials ---\")\n\ntry:\n    # Run the agent, calling train_finetune_trial for each run configuration\n    wandb.agent(SWEEP_ID, function=train_finetune_trial, count=AGENT_RUN_COUNT, project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY)\nexcept KeyboardInterrupt:\n    logging.warning(\"Sweep agent stopped manually (KeyboardInterrupt).\")\nexcept Exception as e:\n    logging.error(f\"W&B Agent execution stopped due to error: {e}\", exc_info=True)\n\nprint(\"--- W&B Agent Finished ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}